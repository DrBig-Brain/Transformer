{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14155426,"sourceType":"datasetVersion","datasetId":9022244}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ddccf292-09ae-4954-9f11-31d1fdc81226","cell_type":"code","source":"import sys\nsys.path.insert(0, \"/kaggle/input/transformer-by-abhinav\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:07.664736Z","iopub.execute_input":"2025-12-15T16:13:07.665019Z","iopub.status.idle":"2025-12-15T16:13:07.673376Z","shell.execute_reply.started":"2025-12-15T16:13:07.664994Z","shell.execute_reply":"2025-12-15T16:13:07.672699Z"}},"outputs":[],"execution_count":1},{"id":"9aac053f","cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/transformer-by-abhinav/spa.txt\", sep=\"\\t\", header=None, names=[\"English\", \"Spanish\", \"Attribution\"], encoding=\"utf-8\")\n\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:07.675034Z","iopub.execute_input":"2025-12-15T16:13:07.675224Z","iopub.status.idle":"2025-12-15T16:13:10.206823Z","shell.execute_reply.started":"2025-12-15T16:13:07.675210Z","shell.execute_reply":"2025-12-15T16:13:10.206076Z"}},"outputs":[{"name":"stdout","text":"  English  Spanish                                        Attribution\n0     Go.      Ve.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n1     Go.    Vete.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n2     Go.    Vaya.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n3     Go.  Váyase.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n4     Hi.    Hola.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n","output_type":"stream"}],"execution_count":2},{"id":"6582dfaa","cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.207923Z","iopub.execute_input":"2025-12-15T16:13:10.208214Z","iopub.status.idle":"2025-12-15T16:13:10.215061Z","shell.execute_reply.started":"2025-12-15T16:13:10.208187Z","shell.execute_reply":"2025-12-15T16:13:10.213929Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(139013, 3)"},"metadata":{}}],"execution_count":3},{"id":"b0542cf6","cell_type":"code","source":"l_eng = []\nfor i in df['English']:\n    l_eng.append(len(i.split(\" \")))\nmax(l_eng)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.216092Z","iopub.execute_input":"2025-12-15T16:13:10.216358Z","iopub.status.idle":"2025-12-15T16:13:10.311244Z","shell.execute_reply.started":"2025-12-15T16:13:10.216333Z","shell.execute_reply":"2025-12-15T16:13:10.310357Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"70"},"metadata":{}}],"execution_count":4},{"id":"b5622591","cell_type":"code","source":"l_spa = []\nfor i in df['Spanish']:\n    l_spa.append(len(i.split(\" \")))\nmax(l_spa)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.312052Z","iopub.execute_input":"2025-12-15T16:13:10.312368Z","iopub.status.idle":"2025-12-15T16:13:10.408628Z","shell.execute_reply.started":"2025-12-15T16:13:10.312342Z","shell.execute_reply":"2025-12-15T16:13:10.407976Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"68"},"metadata":{}}],"execution_count":5},{"id":"318b8da9","cell_type":"code","source":"import re\nen_sent = df['English']\nsp_sent = df['Spanish']\nen_sent = en_sent.apply(lambda x: x.lower())\nsp_sent = sp_sent.apply(lambda x: x.lower())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.409411Z","iopub.execute_input":"2025-12-15T16:13:10.409666Z","iopub.status.idle":"2025-12-15T16:13:10.503702Z","shell.execute_reply.started":"2025-12-15T16:13:10.409641Z","shell.execute_reply":"2025-12-15T16:13:10.503031Z"}},"outputs":[],"execution_count":6},{"id":"d81eb7c0","cell_type":"code","source":"en_sent = en_sent.apply(lambda x: re.sub(r'[,.!?¿¡]', '', x))\nsp_sent = sp_sent.apply(lambda x: re.sub(r'[,.!?¿¡]', '', x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.505607Z","iopub.execute_input":"2025-12-15T16:13:10.505863Z","iopub.status.idle":"2025-12-15T16:13:10.837939Z","shell.execute_reply.started":"2025-12-15T16:13:10.505846Z","shell.execute_reply":"2025-12-15T16:13:10.837328Z"}},"outputs":[],"execution_count":7},{"id":"671384e3","cell_type":"code","source":"sp_sent = sp_sent.apply(lambda x: '<sos>' + x + '<eos>')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.839339Z","iopub.execute_input":"2025-12-15T16:13:10.839578Z","iopub.status.idle":"2025-12-15T16:13:10.880430Z","shell.execute_reply.started":"2025-12-15T16:13:10.839559Z","shell.execute_reply":"2025-12-15T16:13:10.879733Z"}},"outputs":[],"execution_count":8},{"id":"15f4debf","cell_type":"code","source":"from encoder import Encoder\nen_encoder = Encoder(en_sent,max_len = 100)\nsp_encoder = Encoder(sp_sent,max_len = 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:10.881244Z","iopub.execute_input":"2025-12-15T16:13:10.881508Z","iopub.status.idle":"2025-12-15T16:13:15.862439Z","shell.execute_reply.started":"2025-12-15T16:13:10.881483Z","shell.execute_reply":"2025-12-15T16:13:15.861869Z"}},"outputs":[],"execution_count":9},{"id":"7217760c","cell_type":"code","source":"en_encoder.build_vocab()\nlen(en_encoder.vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:15.863107Z","iopub.execute_input":"2025-12-15T16:13:15.863488Z","iopub.status.idle":"2025-12-15T16:13:16.179252Z","shell.execute_reply.started":"2025-12-15T16:13:15.863448Z","shell.execute_reply":"2025-12-15T16:13:16.178431Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"10000"},"metadata":{}}],"execution_count":10},{"id":"02c3fd55","cell_type":"code","source":"sp_encoder.build_vocab()\nlen(sp_encoder.vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:16.180151Z","iopub.execute_input":"2025-12-15T16:13:16.180854Z","iopub.status.idle":"2025-12-15T16:13:16.403888Z","shell.execute_reply.started":"2025-12-15T16:13:16.180831Z","shell.execute_reply":"2025-12-15T16:13:16.403141Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"10000"},"metadata":{}}],"execution_count":11},{"id":"6f09f7d6","cell_type":"code","source":"en_encoded = []\nfor i in en_sent.values:\n    en_encoded.append(en_encoder.encode_text(i))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:16.404690Z","iopub.execute_input":"2025-12-15T16:13:16.405302Z","iopub.status.idle":"2025-12-15T16:13:16.998718Z","shell.execute_reply.started":"2025-12-15T16:13:16.405281Z","shell.execute_reply":"2025-12-15T16:13:16.998109Z"}},"outputs":[],"execution_count":12},{"id":"05ed749c","cell_type":"code","source":"sp_encoded = []\nfor i in sp_sent.values:\n    sp_encoded.append(sp_encoder.encode_text(i))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:16.999818Z","iopub.execute_input":"2025-12-15T16:13:17.000069Z","iopub.status.idle":"2025-12-15T16:13:17.684589Z","shell.execute_reply.started":"2025-12-15T16:13:17.000052Z","shell.execute_reply":"2025-12-15T16:13:17.683955Z"}},"outputs":[],"execution_count":13},{"id":"02f1775d","cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfrom model import Transformer\nimport torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Transformer(10000,10000,128,2,6,2048,100,0.1).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:13:17.685266Z","iopub.execute_input":"2025-12-15T16:13:17.685452Z","iopub.status.idle":"2025-12-15T16:13:18.424953Z","shell.execute_reply.started":"2025-12-15T16:13:17.685439Z","shell.execute_reply":"2025-12-15T16:13:18.424137Z"}},"outputs":[],"execution_count":14},{"id":"302e0c4d","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport time\ncriterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, betas = (0.9,0.98),eps = 1e-9)\n\nen_encoded = torch.tensor(en_encoded)\nsp_encoded = torch.tensor(sp_encoded)\nbatch_size = 128\n\nnum_samples = en_encoded.size(0)\nnum_batches = num_samples // batch_size\n\nfor epoch in range(50):\n    total_loss = 0\n    start = time.time()\n\n    for i in range(0, num_samples, batch_size):\n        src_batch = en_encoded[i:i+batch_size]\n        tgt_batch = sp_encoded[i:i+batch_size]\n        src_batch = src_batch.to(device)\n        tgt_batch = tgt_batch.to(device)\n        src_batch = src_batch.to(device)\n        tgt_batch = tgt_batch.to(device)\n\n        # Teacher forcing: decoder input is tgt[:, :-1]\n        tgt_input = tgt_batch[:, :-1]\n\n        # Model output\n        output = model(src_batch, tgt_input)   # (batch, seq, vocab_size)\n\n        # Target shifted by 1\n        tgt_output = tgt_batch[:, 1:].contiguous().view(-1)\n\n        # Reshape output for loss\n        output = output.contiguous().view(-1, 10000)\n\n        loss = criterion(output, tgt_output)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n    print(\"Training Started\")\n    print(f\"epoch: {epoch+1}, loss: {total_loss/num_batches:.4f}\")\n    print(f\"epoch took:{time.time()-start} seconds\")\nprint(\"Training has ended\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T16:20:35.625357Z","iopub.execute_input":"2025-12-15T16:20:35.625972Z","iopub.status.idle":"2025-12-15T19:03:19.915518Z","shell.execute_reply.started":"2025-12-15T16:20:35.625947Z","shell.execute_reply":"2025-12-15T19:03:19.914765Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/2914600894.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  en_encoded = torch.tensor(en_encoded)\n/tmp/ipykernel_47/2914600894.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  sp_encoded = torch.tensor(sp_encoded)\n","output_type":"stream"},{"name":"stdout","text":"Training Started\nepoch: 1, loss: 4.1201\nepoch took:195.63371753692627 seconds\nTraining Started\nepoch: 2, loss: 3.6500\nepoch took:195.54999423027039 seconds\nTraining Started\nepoch: 3, loss: 3.2801\nepoch took:195.4784643650055 seconds\nTraining Started\nepoch: 4, loss: 2.9850\nepoch took:195.39964699745178 seconds\nTraining Started\nepoch: 5, loss: 2.7494\nepoch took:195.27919101715088 seconds\nTraining Started\nepoch: 6, loss: 2.5490\nepoch took:195.24465322494507 seconds\nTraining Started\nepoch: 7, loss: 2.3767\nepoch took:195.38073134422302 seconds\nTraining Started\nepoch: 8, loss: 2.2336\nepoch took:195.36984634399414 seconds\nTraining Started\nepoch: 9, loss: 2.1073\nepoch took:195.03599762916565 seconds\nTraining Started\nepoch: 10, loss: 1.9954\nepoch took:194.96253967285156 seconds\nTraining Started\nepoch: 11, loss: 1.8964\nepoch took:195.1979911327362 seconds\nTraining Started\nepoch: 12, loss: 1.8055\nepoch took:195.30326390266418 seconds\nTraining Started\nepoch: 13, loss: 1.7281\nepoch took:195.1593885421753 seconds\nTraining Started\nepoch: 14, loss: 1.6543\nepoch took:195.2031877040863 seconds\nTraining Started\nepoch: 15, loss: 1.5907\nepoch took:195.4259250164032 seconds\nTraining Started\nepoch: 16, loss: 1.5284\nepoch took:195.37242436408997 seconds\nTraining Started\nepoch: 17, loss: 1.4751\nepoch took:195.40172839164734 seconds\nTraining Started\nepoch: 18, loss: 1.4240\nepoch took:195.22666311264038 seconds\nTraining Started\nepoch: 19, loss: 1.3747\nepoch took:195.16819548606873 seconds\nTraining Started\nepoch: 20, loss: 1.3354\nepoch took:195.2020881175995 seconds\nTraining Started\nepoch: 21, loss: 1.2927\nepoch took:195.2017002105713 seconds\nTraining Started\nepoch: 22, loss: 1.2580\nepoch took:195.16243743896484 seconds\nTraining Started\nepoch: 23, loss: 1.2250\nepoch took:195.17368698120117 seconds\nTraining Started\nepoch: 24, loss: 1.1908\nepoch took:195.14277935028076 seconds\nTraining Started\nepoch: 25, loss: 1.1598\nepoch took:195.11290502548218 seconds\nTraining Started\nepoch: 26, loss: 1.1316\nepoch took:195.0824909210205 seconds\nTraining Started\nepoch: 27, loss: 1.1069\nepoch took:195.10055780410767 seconds\nTraining Started\nepoch: 28, loss: 1.0834\nepoch took:195.03834915161133 seconds\nTraining Started\nepoch: 29, loss: 1.0553\nepoch took:194.99844026565552 seconds\nTraining Started\nepoch: 30, loss: 1.0351\nepoch took:194.98373579978943 seconds\nTraining Started\nepoch: 31, loss: 1.0103\nepoch took:194.9667911529541 seconds\nTraining Started\nepoch: 32, loss: 0.9897\nepoch took:194.97997450828552 seconds\nTraining Started\nepoch: 33, loss: 0.9738\nepoch took:194.98716235160828 seconds\nTraining Started\nepoch: 34, loss: 0.9538\nepoch took:195.0015528202057 seconds\nTraining Started\nepoch: 35, loss: 0.9339\nepoch took:195.05938625335693 seconds\nTraining Started\nepoch: 36, loss: 0.9160\nepoch took:195.36907577514648 seconds\nTraining Started\nepoch: 37, loss: 0.8983\nepoch took:195.3976821899414 seconds\nTraining Started\nepoch: 38, loss: 0.8838\nepoch took:195.3205487728119 seconds\nTraining Started\nepoch: 39, loss: 0.8693\nepoch took:195.39425659179688 seconds\nTraining Started\nepoch: 40, loss: 0.8587\nepoch took:195.23741579055786 seconds\nTraining Started\nepoch: 41, loss: 0.8401\nepoch took:195.2258894443512 seconds\nTraining Started\nepoch: 42, loss: 0.8292\nepoch took:195.26117324829102 seconds\nTraining Started\nepoch: 43, loss: 0.8186\nepoch took:195.35992407798767 seconds\nTraining Started\nepoch: 44, loss: 0.8029\nepoch took:195.7001051902771 seconds\nTraining Started\nepoch: 45, loss: 0.7920\nepoch took:195.70220398902893 seconds\nTraining Started\nepoch: 46, loss: 0.7818\nepoch took:195.65991926193237 seconds\nTraining Started\nepoch: 47, loss: 0.7712\nepoch took:195.62807059288025 seconds\nTraining Started\nepoch: 48, loss: 0.7629\nepoch took:195.65340185165405 seconds\nTraining Started\nepoch: 49, loss: 0.7509\nepoch took:195.6539945602417 seconds\nTraining Started\nepoch: 50, loss: 0.7439\nepoch took:195.63459014892578 seconds\nTraining has ended\n","output_type":"stream"}],"execution_count":16},{"id":"a1180ba1","cell_type":"code","source":"torch.save(model.state_dict,\"/kaggle/working/model.pth\")\nimport pickle\nwith open(\"/kaggle/working/en_encoder.pkl\",'wb') as f:\n    pickle.dump(en_encoder,f)\nwith open(\"/kaggle/working/sp_encoder\",'wb') as f:\n    pickle.dump(sp_encoder,f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T19:03:20.086090Z","iopub.execute_input":"2025-12-15T19:03:20.086274Z","iopub.status.idle":"2025-12-15T19:03:20.272501Z","shell.execute_reply.started":"2025-12-15T19:03:20.086260Z","shell.execute_reply":"2025-12-15T19:03:20.271688Z"}},"outputs":[],"execution_count":18}]}